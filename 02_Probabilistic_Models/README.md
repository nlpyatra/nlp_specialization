# Natural Language Processing Specialization

NLP set of courses from [Coursera](https://www.coursera.org/specializations/natural-language-processing).

## Course 2. Probabilistic Models in NLP

**1. Auto-correct using Minimum Edit Distance**
  - Vocabulary creation, text preprocessing, word counts
  - string manipulation: split, delete, swap, edit
  - Minumum edit distance: Dynamic programming
  - Create a simple auto-correct algorithm using minimum edit distance and dynamic programming

**2. Part-of-Speech (POS) Tagging**
  - Apply the Viterbi algorithm for POS tagging, which is important for computational linguistics

**3. N-gram Language Models**
  - Implement N-grams Corpus preprocessing
  - Implement building a language model: Probability matrix, Perplexity
  - Out of Vocabulary (OOV) words, Smooting, Back-off, interpolation
  - Write a better auto-complete algorithm using an N-gram model (similar models are used for translation, determining the author of a text, and speech recognition)

**4. Word2Vec and Stochastic Gradient Descent**
  - Word Embeddings: Tokenization, Sliding window of words, Transforming words to vectors, One-hot word vectors, Context word vectors
  - Continuous Bag of Words (CBOW) model : Implementation and training
  - Write your own Word2Vec model that uses a neural network to compute word embeddings using a continuous bag-of-words model
